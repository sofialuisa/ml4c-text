{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generadores de poesía\n",
    "\n",
    "Por [Allison Parrish](http://www.decontextualize.com/)\n",
    "\n",
    "Este cuaderno tiene algunas implementaciones de Python de varios generadores de poesía antiguos y conocidos, incluidos * A House of Dust * de Knowles y Tenney, el generador de cartas de amor de Strachey y * Taroko Gorge * de Nick Montfort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como hacer un poema dadá\n",
    "\n",
    "Original escrito por [Tristan Tzara](http://www.391.org/manifestos/1920-dada-manifesto-feeble-love-bitter-love-tristan-tzara.html#.WnPkJYJOndd) en 1920."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "es\n",
      "cr\n",
      "ib\n",
      "e \n",
      "aq\n",
      "uí\n",
      "tu\n",
      "te\n",
      "xt\n",
      "o\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import textwrap\n",
    "\n",
    "mitexto = \"\"\"\n",
    "escribe aquí tu texto\"\"\"\n",
    "\n",
    "palabras = mitexto.split()\n",
    "random.shuffle(palabras)\n",
    "\n",
    "# esto mezcla todas las palabras y las une en un texto con frases de x cantidad de letras por linea\n",
    "# el número tiene que ser mayor a 0\n",
    "print(textwrap.fill(\" \".join(palabras), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A House of Dust\n",
    "\n",
    "Original written in Fortran in 1967 by Alison Knowles and James Tenney. [ELMCIP entry](https://elmcip.net/creative-work/house-dust). [More information](http://blog.calarts.edu/2009/09/10/alison-knowles-james-tenney-and-the-house-of-dust-at-calarts/). [Watch Alison Knowles read from this piece](https://www.youtube.com/watch?v=-68Z708lFsY)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HW Note:\n",
    "The inputs are inspired by the setting of my new workplace, the Equipment Room at ITP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista1 = [\n",
    "    'a',\n",
    "    'b'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista2 = [\n",
    "    'c',\n",
    "    'd'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista3 = [\n",
    "    'e',\n",
    "    'f'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista4 = [\n",
    "    'g',\n",
    "    'h',\n",
    "    'i'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A room of a\n",
      "     c\n",
      "          under f\n",
      "                inhabited by g\n",
      "\n",
      "A room of b\n",
      "     c\n",
      "          under f\n",
      "                inhabited by i\n",
      "\n",
      "A room of a\n",
      "     d\n",
      "          under e\n",
      "                inhabited by i\n",
      "\n",
      "A room of b\n",
      "     c\n",
      "          under f\n",
      "                inhabited by g\n",
      "\n",
      "A room of b\n",
      "     c\n",
      "          under f\n",
      "                inhabited by i\n",
      "\n",
      "A room of b\n",
      "     d\n",
      "          under f\n",
      "                inhabited by i\n",
      "\n",
      "A room of a\n",
      "     d\n",
      "          under f\n",
      "                inhabited by g\n"
     ]
    }
   ],
   "source": [
    "stanza_count = 7\n",
    "for i in range(stanza_count):\n",
    "    print()\n",
    "    print(\"A room of \" + random.choice(lista1))\n",
    "    print(\"     \" + random.choice(lista2))\n",
    "    print(\"          under \" + random.choice(lista3))\n",
    "    print(\"                inhabited by \" + random.choice(lista4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Love Letter Generator\n",
    "\n",
    "Original by Christopher Strachey, written for the Manchester Mark I in 1952. [Read more here](https://grandtextauto.soe.ucsc.edu/2005/08/01/christopher-strachey-first-digital-artist/).\n",
    "\n",
    "Vocabulary based on [this implementation](https://github.com/gingerbeardman/loveletter/blob/master/index.php)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HW Note:\n",
    "I'm gonna try to make a hate letter instead... ¯\\_(ツ)_/¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sal_adjs = [\n",
    "    \"Abominable\",\n",
    "    \"Execrable\",\n",
    "    \"Abhorrent\",\n",
    "    \"Repugnant\",\n",
    "    \"Horrible\",\n",
    "    \"Disgraceful\",\n",
    "    \"Shameful\"\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sal_nouns = [\n",
    "    \"Shit\",\n",
    "    \"Asshole\",\n",
    "    \"Fartface\",\n",
    "    \"Idiot\",\n",
    "    \"Imbecile\",\n",
    "    \"Douchebag\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjs = [\n",
    "    'helpless',\n",
    "    'lazy',\n",
    "    'obnoxious',\n",
    "    'pitiful',\n",
    "    'repulsive',\n",
    "    'thoughtless'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns = [\n",
    "    'disease',\n",
    "    'nausea',\n",
    "    'repulsion',\n",
    "    'vomit',\n",
    "    'shit'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "advs = [\n",
    "    'lifelessly',\n",
    "    'remorsefully',\n",
    "    'ruthlessly'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs = [\n",
    "    'hates',\n",
    "    'disgraces',\n",
    "    'shames',\n",
    "    'deslikes',\n",
    "    'dishonors',\n",
    "    'degrades'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abhorrent Imbecile,\n",
      "\n",
      "My helpless vomit remorsefully degrades your thoughtless\n",
      "nausea. You are my repulsive repulsion. My disease hates\n",
      "your repulsive vomit. My obnoxious vomit remorsefully\n",
      "dishonors your repulsion. My nausea ruthlessly deslikes your\n",
      "thoughtless shit.\n",
      "\n",
      "Yours lifelessly,\n",
      "Sofía by M.U.C.\n"
     ]
    }
   ],
   "source": [
    "# textwrap library used to \"wrap\" the text at a particular length\n",
    "import textwrap\n",
    "\n",
    "# output begins with salutation\n",
    "output = random.choice(sal_adjs) + \" \" + random.choice(sal_nouns) + \",\\n\"\n",
    "output += \"\\n\"\n",
    "\n",
    "# inside this loop, build the phrases. strachey implemented \"short\" phrases\n",
    "# and \"long\" phrases; two or more \"short\" phrases in a row have special\n",
    "# formatting rules, so we need to know what the last phrase kind was in\n",
    "# order to generate the output.\n",
    "history = []\n",
    "body = \"\"\n",
    "for i in range(5):\n",
    "    kind = random.choice([\"short\", \"long\"])\n",
    "    if kind == \"long\":\n",
    "        # adjectives and adverbs will be present only 50% of the time\n",
    "        line = \" \".join([\n",
    "            \"My\",\n",
    "            random.choice([random.choice(adjs), \"\"]),\n",
    "            random.choice(nouns),\n",
    "            random.choice([random.choice(advs), \"\"]),\n",
    "            random.choice(verbs),\n",
    "            \"your\",\n",
    "            random.choice([random.choice(adjs), \"\"]),\n",
    "            random.choice(nouns)])\n",
    "        body += line\n",
    "    else:\n",
    "        adj_noun = random.choice(adjs) + \" \" + random.choice(nouns)\n",
    "        # if the last phrase was \"short,\" use truncated form\n",
    "        if len(history) > 0 and history[-1] == \"short\":\n",
    "            body += \": my \" + adj_noun\n",
    "        else:\n",
    "            body += \"You are my \" + adj_noun\n",
    "    body += \". \"\n",
    "    history.append(kind)\n",
    "# clean up output\n",
    "body = body.replace(\"  \", \" \")\n",
    "body = body.replace(\". :\", \":\")\n",
    "# put everything together\n",
    "output += textwrap.fill(body, 60)\n",
    "output += \"\\n\\nYours \" + random.choice(advs) + \",\\n\"\n",
    "output += \"Sofía by M.U.C.\"\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
